{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xNjaEFXPp2PR"},"outputs":[],"source":["!pip install -q auto-gptq transformers accelerate optimum"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"kpZBHZGmisMr"},"outputs":[],"source":["!pip install optimum"]},{"cell_type":"code","source":["!pip install auto-gptq"],"metadata":{"collapsed":true,"id":"6W4vj5kmFoeV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zeasmoWMKuX"},"outputs":[],"source":["# git ì—°ë™\n","!git clone https://github.com/CampusChatBot-Team5/Termproject_5.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qOsLII9VskHE"},"outputs":[],"source":["# íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","import torch\n","import json\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from google.colab import files\n","import pandas as pd\n","from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"2NwhmNTTslNS"},"outputs":[],"source":["# ëª¨ë¸ ë¡œë“œ 8B -> 4bit ì–‘ìí™” LLama ê¸°ë°˜ (í•œêµ­ì–´ ëª¨ë¸)\n","model_name = \"allganize/Llama-3-Alpha-Ko-8B-Instruct-GPTQ\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=\"auto\",\n","    torch_dtype=\"auto\",\n","    trust_remote_code=True\n",")\n","\n","model = prepare_model_for_kbit_training(model)\n","lora_cfg = LoraConfig(r=8, lora_alpha=32, target_modules=[\"q_proj\",\"v_proj\"], bias=\"none\")\n","model = get_peft_model(model, lora_cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8SExWrKsunQ"},"outputs":[],"source":["#LLM -> í•™êµ ê³µì§€, í•™ì‚¬ ì¼ì • ê´€ë ¨ ë¶„ë¥˜ ëª¨í˜¸í•˜ê²Œí•¨\n","# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n","system_prompt = \"\"\"\\\n","ë„ˆëŠ” ì¶©ë‚¨ëŒ€í•™êµ ê´€ë ¨ ì§ˆë¬¸ì„ ì•„ë˜ ë‹¤ì„¯ ê°œ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ” ë¶„ë¥˜ê¸°ì•¼.\n","ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ë°˜ë“œì‹œ í•´ë‹¹ë˜ëŠ” **ìˆ«ì í•˜ë‚˜ë§Œ** ì¶œë ¥í•´ì•¼ í•´.\n","\n","[ì¹´í…Œê³ ë¦¬ ëª©ë¡]\n","0: ì¡¸ì—…ìš”ê±´ â€“ ì¡¸ì—…, í•™ì  ì´ìˆ˜, ì¸ì¦, ì¡¸ì—…ì‹œí—˜\n","1: í•™êµê³µì§€ â€“ ì¥í•™ê¸ˆ, ê³µëª¨ì „, íŠ¹ê°•, ì˜ˆë¹„êµ°, ë“±ë¡ê¸ˆ, í–‰ì‚¬\n","2: í•™ì‚¬ì¼ì • â€“ ê°œê°•, ì¢…ê°•, ìˆ˜ê°•ì‹ ì²­, ì •ì •ê¸°ê°„, ë°©í•™, ì„±ì \n","3: ì‹ë‹¨ì•ˆë‚´ â€“ ì˜¤ëŠ˜ ì‹ë‹¨, í•™ì‹ ë©”ë‰´, ì ì‹¬, ì €ë…, ê±´ê°•ì‹\n","4: í†µí•™ë²„ìŠ¤ â€“ ë²„ìŠ¤ ì‹œê°„, ë…¸ì„ , ì •ë¥˜ì¥, ìš´í–‰\n","\n","ì ˆëŒ€ë¡œ ì„¤ëª…í•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ ìˆ«ì í•˜ë‚˜ë§Œ ì¶œë ¥í•´.\n","\"\"\"\n","\n","# few-shot\n","fewshot_examples = [\n","    {\"role\": \"user\", \"content\": \"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë‚˜ì™€?\"}, {\"role\": \"assistant\", \"content\": \"3\"},\n","    {\"role\": \"user\", \"content\": \"ì˜ˆë¹„êµ° í›ˆë ¨ ì–´ë–»ê²Œ ì‹ ì²­í•´?\"}, {\"role\": \"assistant\", \"content\": \"1\"},\n","    {\"role\": \"user\", \"content\": \"ì¡¸ì—…í•˜ë ¤ë©´ ëª‡ í•™ì  ë“¤ì–´ì•¼ í•´?\"}, {\"role\": \"assistant\", \"content\": \"0\"},\n","    {\"role\": \"user\", \"content\": \"í†µí•™ë²„ìŠ¤ ì‹œê°„í‘œ ì¢€ ì•Œë ¤ì¤˜\"}, {\"role\": \"assistant\", \"content\": \"4\"},\n","    {\"role\": \"user\", \"content\": \"ìˆ˜ê°•ì‹ ì²­ ê¸°ê°„ì´ ì–¸ì œì•¼?\"}, {\"role\": \"assistant\", \"content\": \"2\"},\n","]\n","\n","# systemì— í”„ë¡¬í”„íŠ¸ì™€ few_shot ë„£ì–´ì£¼ëŠ” ë°©ì‹\n","def build_messages_with_fewshot(question: str):\n","    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n","    messages += fewshot_examples\n","    messages.append({\"role\": \"user\", \"content\": question})\n","    return messages\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRkjLZgbtAHv"},"outputs":[],"source":["def generate_answer(question, max_new_tokens=5):\n","    messages = build_messages_with_fewshot(question)\n","\n","    input_ids = tokenizer.apply_chat_template(\n","        messages,\n","        add_generation_prompt=True,\n","        return_tensors=\"pt\"\n","    ).to(model.device)\n","\n","    outputs = model.generate(\n","        input_ids,\n","        max_new_tokens=max_new_tokens,\n","        do_sample=False,\n","        eos_token_id=tokenizer.eos_token_id,\n","        repetition_penalty=1.05,\n","    )\n","\n","    response = outputs[0][input_ids.shape[-1]:]\n","    return tokenizer.decode(response, skip_special_tokens=True)\n","\n","\n","def classify_question(question, retries=3):\n","    for _ in range(retries):\n","        output = generate_answer(question, max_new_tokens=5)\n","        try:\n","            result = output.strip().split()[0]\n","        except:\n","            continue\n","        if result in ['0', '1', '2', '3', '4']:\n","            return result\n","    return \"ì˜ˆì¸¡ ì‹¤íŒ¨\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTuS3fdptB2Z"},"outputs":[],"source":["def make_prompt(question):\n","    return question  # ì§ì ‘ ì‚¬ìš© ì•ˆí•¨ (ChatML ì‚¬ìš© ì¤‘)\n","\n","def keyword_or_llm_classify(question, alpha_if_keyword=0.9):\n","    q = question.lower()\n","    keyword_map = {\n","        0: [\"ì¡¸ì—…\", \"ì´ìˆ˜\", \"í•™ì \", \"ì¸ì¦\", \"ì‹œí—˜\"],\n","        1: [\"ì¥í•™ê¸ˆ\", \"ê³µì§€\", \"ì˜ˆë¹„êµ°\", \"ë“±ë¡ê¸ˆ\", \"ê³µëª¨ì „\", \"íŠ¹ê°•\"],\n","        2: [\"ê°œê°•\", \"ì¢…ê°•\", \"ë°©í•™\", \"ìˆ˜ê°•\", \"ì„±ì \", \"ì •ì •\", \"í•™ì‚¬\", \"íœ´ê°•\"],\n","        3: [\"í•™ì‹\", \"ë©”ë‰´\", \"ì ì‹¬\", \"ì €ë…\", \"ì‹ë‹¹\", \"ë‹¤ì´ì–´íŠ¸\", \"ê±´ê°•\", \"ì‹ë‹¨\"],\n","        4: [\"ë²„ìŠ¤\", \"í†µí•™\", \"ì •ë¥˜ì¥\", \"ë…¸ì„ \", \"ìš´í–‰\"]\n","    }\n","\n","    keyword_scores = [0] * 5\n","    for label, keywords in keyword_map.items():\n","        keyword_scores[label] = sum(1 for kw in keywords if kw in q)\n","\n","    total_kw = sum(keyword_scores)\n","    keyword_probs = [s / total_kw for s in keyword_scores] if total_kw > 0 else [0] * 5\n","    alpha = alpha_if_keyword if total_kw > 0 else 0.0\n","\n","    result = classify_question(question)\n","    llm_probs = [0] * 5\n","    if result in ['0', '1', '2', '3', '4']:\n","        llm_probs[int(result)] = 1\n","\n","    final_scores = [alpha * kw + (1 - alpha) * llm for kw, llm in zip(keyword_probs, llm_probs)]\n","\n","    print(\"question:\", question)\n","    print(\"keyword_scores:\", keyword_scores)\n","    print(\"LLM result:\", result)\n","    print(\"final_scores:\", final_scores)\n","\n","    return str(final_scores.index(max(final_scores)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9BeqBKOlUc8"},"outputs":[],"source":["question = \"ê³„ì ˆí•™ê¸° ì–¸ì œì„?\"\n","predicted_label = keyword_or_llm_classify(question)\n","print(\"ìµœì¢… ì˜ˆì¸¡ ë¼ë²¨:\", predicted_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lT1QasnTtHWs"},"outputs":[],"source":["# ë°ì´í„° ì—…ë¡œë“œ\n","file_path = \"/content/drive/MyDrive/data/test_cls_edit.json\"\n","\n","with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","    dataset = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"OqsGD5P75C1h"},"outputs":[],"source":["dataset[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kYBY3dz3tOg9"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","import pandas as pd\n","\n","y_true = []\n","y_pred = []\n","misclassified = []\n","fail_count = 0  # ì˜ˆì¸¡ ì‹¤íŒ¨ ê°œìˆ˜\n","\n","for sample in dataset:\n","    true_label = str(sample[\"label\"])\n","    question = sample[\"question\"]\n","    pred_label = keyword_or_llm_classify(question)\n","\n","    if pred_label == \"ì˜ˆì¸¡ ì‹¤íŒ¨\":\n","        fail_count += 1\n","        continue\n","\n","    y_true.append(true_label)\n","    y_pred.append(pred_label)\n","\n","    if true_label != pred_label:\n","        misclassified.append((question, true_label, pred_label))\n","\n","# ì „ì²´ ì„±ëŠ¥ ì§€í‘œ\n","accuracy = accuracy_score(y_true, y_pred)\n","precision = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n","recall = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n","f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n","\n","# ë¼ë²¨ë³„ ìƒì„¸ ì§€í‘œ\n","report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n","df_report = pd.DataFrame(report).transpose()\n","df_report = df_report.loc[['0', '1', '2', '3', '4']]\n","\n","# ì •í™•ë„ ê³„ì‚°\n","correct_counts = {str(i): 0 for i in range(5)}\n","total_counts = {str(i): 0 for i in range(5)}\n","for yt, yp in zip(y_true, y_pred):\n","    total_counts[yt] += 1\n","    if yt == yp:\n","        correct_counts[yt] += 1\n","df_report[\"accuracy\"] = [\n","    correct_counts[label] / total_counts[label] if total_counts[label] else 0.0\n","    for label in df_report.index\n","]\n","\n","# ì¶œë ¥\n","print(\"\\nğŸ“Š ì „ì²´ í‰ê°€ ì§€í‘œ\")\n","print(f\"- Accuracy:  {accuracy:.4f}\")\n","print(f\"- Precision: {precision:.4f}\")\n","print(f\"- Recall:    {recall:.4f}\")\n","print(f\"- F1 Score:  {f1:.4f}\")\n","\n","print(\"\\nğŸ“Œ ë¼ë²¨ë³„ ì„±ëŠ¥ ì§€í‘œ\")\n","print(df_report[[\"precision\", \"recall\", \"f1-score\", \"accuracy\"]])\n","\n","print(f\"\\nâŒ ì˜ëª» ë¶„ë¥˜ëœ ìƒ˜í”Œ ìˆ˜: {len(misclassified)}ê°œ\")\n","for i, (question, true_label, pred_label) in enumerate(misclassified[:10]):\n","    print(f\"{i+1}. Q: {question} â†’ ì‹¤ì œ: {true_label}, ì˜ˆì¸¡: {pred_label}\")\n","\n","print(f\"\\nâš ï¸ ì˜ˆì¸¡ ì‹¤íŒ¨í•œ ìƒ˜í”Œ ìˆ˜: {fail_count}ê°œ\")\n"]},{"cell_type":"code","source":["#ì¡¸ì—…â€ í‚¤ì›Œë“œ ê³¼ì í•© â†’ label 0 ê³¼ì‰ ë¶„ë¥˜\n","#â€œì–¸ì œ ë–´ë‚˜ìš”?â€, â€œê³µì§€ ì˜¬ë¼ì™”ì–´ìš”?â€ â†’ ëŒ€ë¶€ë¶„ label 1 (ê³µì§€ì„±) â†’ LLM í”„ë¡¬í”„íŠ¸ ë³´ê°• í•„ìš”\n","# ì„±ì  ì •ì • ê°€ëŠ¥í•œ ê¸°ê°„ ê³µì§€ëë‚˜ìš”? label 1 , label 2 ì–´ë–¤ê±°??"],"metadata":{"id":"JLbNIv7Hjqso"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AdMgHVlvB5jW"},"source":["## í”„ëŒí”„íŠ¸ íŠœë‹\n","labelë§Œ ì¶œë ¥í•˜ë„ë¡ í”„ëŒí”„íŠ¸ë¥¼ ì„¤ê³„, ëª¨ë¸ì´ labelì„ ì¶œë ¥í•˜ì§€ ì•Šì„ ê²½ìš° ê³„ì† ìš”ì²­\n","JSON í˜•ì‹ ê°•ì œ\n","ì¤‘ë¦½ ë‹µë³€ ë°©ì§€: \"There is no neutral answer\" ëª…ì‹œ\n","ë¶€ì •í™•í•œ ì‘ë‹µ ëŒ€ë¹„: \"neutral\", \"mixed\" ê°™ì€ ì˜ëª»ëœ ë‹µë³€ ë°©ì§€ ë¬¸êµ¬ ì‚½ì…\n","ì¬ì‹œë„ ë£¨í”„ êµ¬ì„±: ì˜ëª»ëœ ì‘ë‹µì´ ë‚˜ì˜¬ ê²½ìš°, ë°˜ë³µí•´ì„œ ì¬ìš”ì²­í•¨\n","\n","â†’ ëª¨ë¸ ì‘ë‹µ ì‹¤íŒ¨ìœ¨ì„ ë‚®ì¶”ê³ , ì¼ê´€ì„± ìˆëŠ” ì‘ë‹µì„ ìœ ë„\n","\n","## voting ë°©ì‹\n","ë‹¨ì¼ LLM ê²°ê³¼ ëŒ€ì‹  ì—¬ëŸ¬ LLMì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì¢…í•©í•´ ìµœì¢… íŒë‹¨.\n","ì ìš©ëœ ë°©ë²•:\n","Hard Voting: 5ê°œ ëª¨ë¸ ì¤‘ ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë¼ë²¨ì„ ì„ íƒ\n","Soft Voting: ëª¨ë¸ë“¤ì˜ í™•ë¥  ê¸°ë°˜ ì‘ë‹µ í‰ê· ìœ¼ë¡œ ê°€ì¥ í™•ë¥  ë†’ì€ ë¼ë²¨ ì„ íƒ\n","â†’ íŠ¹íˆ ì„±ëŠ¥ ë‚®ì€ ëª¨ë¸ë“¤ì˜ soft voting ê²°ê³¼ê°€ ë‹¨ë… ëª¨ë¸ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì„\n","\n","## í‚¤ì›Œë“œ ê¸°ë°˜\n","labelì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê·¸ labelë¡œ ë¶„ë¥˜í•¨.\n","\n","-> í‚¤ì›Œë“œ ë¶„ë¥˜ ë‹µ + LLMì´ ë¶„ë¥˜í•œ ë‹µ\n","\n","ì˜¤ëŠ˜ 2í•™ë©”ë‰´ ë­ì•¼? -> ë©”ë‰´ í‚¤ì›Œë“œ ë„ì¶œì´ ì•ˆë¨\n","\n","í˜•íƒœì†Œ ë¶„ì„ê¸°ë¡œ ë¶„ë¥˜ë¥¼ í•´ì¤˜ì•¼ í•˜ë‚˜??"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1N3WWplke743h0XRAHfKVZZpxa92lhi88","timestamp":1749734914576}],"mount_file_id":"1N3WWplke743h0XRAHfKVZZpxa92lhi88","authorship_tag":"ABX9TyPsyAQpewgWGI//98uYEuJY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}